{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14db7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tensordict.tensordict import TensorDict\n",
    "import sys\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f056d359",
   "metadata": {},
   "source": [
    "# Creating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b056c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=200000, n_features=3, n_informative=3, n_redundant=0,\n",
    "                           n_clusters_per_class=1, weights=[0.5, 0.5], flip_y=0.05, class_sep=1.5)\n",
    "y = 2*y - 1\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "# ax.scatter(X[y == -1][:, 0], X[y == -1][:, 1], X[y == -1][:, 2], c='b', marker='o', label='Class -1')\n",
    "# ax.scatter(X[y == 1][:, 0], X[y == 1][:, 1], X[y == 1][:, 2], c='r', marker='^', label='Class 1')\n",
    "\n",
    "# ax.set_xlabel('Feature 1')\n",
    "# ax.set_ylabel('Feature 2')\n",
    "# ax.set_zlabel('Feature 3')\n",
    "# ax.set_title('3D Scatter Plot of Synthetic Data')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4bdb8",
   "metadata": {},
   "source": [
    "# LFs generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1203ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_label_flip_and_zero(arr, m, n_list, zero_n_list):\n",
    "\n",
    "    if len(n_list) != m or len(zero_n_list) != m:\n",
    "        raise ValueError(\"The length of n_list and zero_n_list must be equal to m.\")\n",
    "    \n",
    "    length = len(arr)\n",
    "    flipped_arrays = []\n",
    "\n",
    "    for i in range(m):\n",
    "        n = n_list[i]\n",
    "        zero_n = zero_n_list[i]\n",
    "\n",
    "        # Randomly select indices to flip\n",
    "        indices_to_zero = np.random.choice(length, zero_n, replace=False)\n",
    "\n",
    "        # Create a copy of the array to flip the labels\n",
    "        modified_arr = arr.copy()\n",
    "        modified_arr[indices_to_zero] = 0\n",
    "\n",
    "        # Identify the untouched indices\n",
    "        untouched_indices = np.setdiff1d(np.arange(length), indices_to_zero)\n",
    "\n",
    "        # Randomly select indices from the untouched indices to set to 0\n",
    "        indices_to_flip = np.random.choice(untouched_indices, n, replace=False)\n",
    "\n",
    "        # Set the chosen indices to 0\n",
    "        modified_arr[indices_to_flip] = -modified_arr[indices_to_flip]\n",
    "\n",
    "        flipped_arrays.append(modified_arr)\n",
    "\n",
    "    return flipped_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0804db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = y\n",
    "\n",
    "m = 5  \n",
    "\n",
    "\n",
    "beta_list = [0.4 for i in range(m)]\n",
    "zero_n_list = [int((1 - beta)* y.shape[0]) for beta in beta_list]  \n",
    "\n",
    "alpha_list = [0.89 for i in range(m)]\n",
    "n_list = [int((1-alpha)*(y.shape[0] - zero_n_list[i])) for i, alpha in enumerate(alpha_list)] \n",
    "\n",
    "# m = 5\n",
    "# beta_list = [0.35, 0.39, 0.42, 0.46, 0.5]\n",
    "# zero_n_list = [int((1 - beta)* y.shape[0]) for beta in beta_list]  \n",
    "\n",
    "# alpha_list = [0.81, 0.82, 0.84, 0.86, 0.90]\n",
    "# n_list = [int((1-alpha)*(y.shape[0] - zero_n_list[i])) for i, alpha in enumerate(alpha_list)] \n",
    "\n",
    "# print(n_list)\n",
    "\n",
    "flipped_arrays = random_label_flip_and_zero(arr, m, n_list, zero_n_list)\n",
    "\n",
    "\n",
    "# print(\"Original = \", arr)\n",
    "ALL_LFs = {}\n",
    "\n",
    "for i, modified_arr in enumerate(flipped_arrays):\n",
    "#     print(f\"Array {i+1}:\")\n",
    "#     print(modified_arr-arr)\n",
    "    lf_dict = {}\n",
    "    \n",
    "    lf_dict['alpha'] = 1 - (n_list[i]/(len(y) - zero_n_list[i]))\n",
    "    lf_dict['beta'] = 1 - (zero_n_list[i]/len(y))\n",
    "    \n",
    "    lf_dict['outputs'] = modified_arr\n",
    "    \n",
    "    ALL_LFs[i] = lf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866b05fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'alpha': 0.8900125,\n",
       "  'beta': 0.4,\n",
       "  'outputs': array([ 1,  0,  0, ...,  0,  0, -1])},\n",
       " 1: {'alpha': 0.8900125,\n",
       "  'beta': 0.4,\n",
       "  'outputs': array([0, 0, 1, ..., 0, 1, 0])},\n",
       " 2: {'alpha': 0.8900125,\n",
       "  'beta': 0.4,\n",
       "  'outputs': array([0, 0, 1, ..., 0, 1, 0])},\n",
       " 3: {'alpha': 0.8900125,\n",
       "  'beta': 0.4,\n",
       "  'outputs': array([1, 0, 0, ..., 0, 1, 0])},\n",
       " 4: {'alpha': 0.8900125,\n",
       "  'beta': 0.4,\n",
       "  'outputs': array([-1,  1,  1, ..., -1,  0,  0])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f4a5a",
   "metadata": {},
   "source": [
    "# Expected Value for alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b765b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum cardinality =  100157.42151665727\n",
      "current cardinality =  200000\n",
      "Check!\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "epsilon = 0.1\n",
    "s_cardinality = len(y)\n",
    "\n",
    "minimum_cardinality = (356/(epsilon)**2) * np.log(m/(3*epsilon))\n",
    "\n",
    "print(\"minimum cardinality = \", minimum_cardinality)\n",
    "print(\"current cardinality = \", s_cardinality)\n",
    "if s_cardinality > minimum_cardinality:\n",
    "    print(\"Check!\")\n",
    "else:\n",
    "    print(\"More data needed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b4da9",
   "metadata": {},
   "source": [
    "# Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4504a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing\n",
    "\n",
    "Alpha_Beta_numpy = np.random.rand(m,2)\n",
    "Alpha_Beta = torch.tensor(Alpha_Beta_numpy, requires_grad=True)\n",
    "\n",
    "class LabelModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelModel, self).__init__()\n",
    "#         self.sigmoid = torch.sigmoid()\n",
    "        Alpha_Beta_numpy = np.random.rand(m,2)\n",
    "        self.alpha_beta_array = nn.Parameter(torch.tensor(Alpha_Beta_numpy, requires_grad=True))\n",
    "        \n",
    "    def forward(self, lf_label, true_label):\n",
    "        \n",
    "        all_lf_probls = 1\n",
    "        \n",
    "        for lf_index in range(self.alpha_beta_array.shape[0]):\n",
    "            \n",
    "            lf_alpha = torch.sigmoid(self.alpha_beta_array[lf_index,0])\n",
    "            lf_beta = torch.sigmoid(self.alpha_beta_array[lf_index,1])\n",
    "            \n",
    "            if lf_label[lf_index] == true_label:\n",
    "                \n",
    "                lf_prob = lf_alpha * lf_beta\n",
    "            \n",
    "            if lf_label[lf_index] == -true_label:\n",
    "                \n",
    "                lf_prob = (1 - lf_alpha) * lf_beta\n",
    "            \n",
    "            if lf_label[lf_index] == 0:\n",
    "                \n",
    "                lf_prob = 1 - lf_beta\n",
    "        \n",
    "            all_lf_probls = all_lf_probls * lf_prob\n",
    "        \n",
    "        \n",
    "        return 0.5 * all_lf_probls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518212eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LabelModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(alpha_beta_array=test_lf,\n",
    "      lf_label=test_lf_label,\n",
    "      true_label=test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b1d47",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4500b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LF_Output_Dataset(Dataset):\n",
    "    def __init__(self, ALL_LFs, X):\n",
    "        \n",
    "        self.ALL_LFs = ALL_LFs\n",
    "        self.X = X\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data_sample = self.X[idx]\n",
    "        lf_outputs = []\n",
    "        \n",
    "        for key in self.ALL_LFs.keys():\n",
    "            \n",
    "            lf_outputs.append(self.ALL_LFs[key]['outputs'][idx])\n",
    "        \n",
    "        return data_sample, lf_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0cafe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LF_Output_Dataset(ALL_LFs, X)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f11f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27393e7d",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c7d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstmmc\u001b[0m (\u001b[33mtousi-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macula/SMATousi/snorkel/attention_snorkel/wandb/run-20240625_121859-w04zktnz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tousi-team/Snorkel-Repro/runs/w04zktnz' target=\"_blank\">Data-200k-epochs-1000-m-5-alpha89-beta40-lre-5</a></strong> to <a href='https://wandb.ai/tousi-team/Snorkel-Repro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tousi-team/Snorkel-Repro' target=\"_blank\">https://wandb.ai/tousi-team/Snorkel-Repro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tousi-team/Snorkel-Repro/runs/w04zktnz' target=\"_blank\">https://wandb.ai/tousi-team/Snorkel-Repro/runs/w04zktnz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:45<00:00, 4379.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = -1017856.5271820395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:43<00:00, 4607.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = -955724.9289879171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:43<00:00, 4612.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = -937186.0946716696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4679.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = -930132.861657722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4676.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = -926053.1973128343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4665.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = -922887.4031250047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4684.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = -920146.2485488243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4710.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = -917715.9668289942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4733.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = -915565.3636297758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4699.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = -913675.642526558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4686.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = -912026.1621071493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4673.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss = -910593.6299282257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4718.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss = -909353.8029337397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4669.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss = -908283.0613469109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4694.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss = -907359.4049466652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4714.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss = -906562.9488096421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4723.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss = -905876.0792010734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:43<00:00, 4629.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss = -905283.4052653826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4658.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss = -904771.6010844206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4673.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss = -904329.1983337925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4703.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss = -903946.365490995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4721.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss = -903614.6936846498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4695.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss = -903326.9993766183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4681.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss = -903077.1481132928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4669.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss = -902859.9002034048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4686.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss = -902670.7773914865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4716.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss = -902505.9486172023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4730.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss = -902362.1327509132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4702.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss = -902236.5160470778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4656.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss = -902126.6822445426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4715.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss = -902030.5534695648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4696.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Loss = -901946.3402481237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:42<00:00, 4716.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss = -901872.4992477543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [00:43<00:00, 4612.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss = -901807.6975094998\n"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "    project='Snorkel-Repro', name='Data-200k-epochs-1000-m-5-alpha89-beta40-lre-5'\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        # config={\n",
    "        # \"learning_rate\": 0.02,\n",
    "        # \"architecture\": \"CNN\",\n",
    "        # \"dataset\": \"CIFAR-100\",\n",
    "        # \"epochs\": 20,\n",
    "        # }\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LabelModel()\n",
    "\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    initial_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for data_sample, lf_outputs in tqdm(data_loader):\n",
    "        \n",
    "#         lf_outputs = [par.to(device) for par in lf_outputs]\n",
    "        \n",
    "        marginal_prob = model(lf_outputs, true_label=1) + model(lf_outputs, true_label=-1)\n",
    "        log_marginal_prob = torch.log(marginal_prob)\n",
    "        initial_loss = initial_loss + log_marginal_prob\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "#         break\n",
    "    \n",
    "    initial_loss = -initial_loss\n",
    "    initial_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {-initial_loss.item()}\")\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            tensor_dict = {f'Params/tensor_{i}_{j}': torch.sigmoid(param[i, j]).item() for i in range(param.size(0)) for j in range(param.size(1))}\n",
    "            wandb.log({\"Prob/Prob\":-initial_loss.item()})\n",
    "            wandb.log(tensor_dict)\n",
    "#             print(torch.sigmoid(param),flush=True)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ec93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b48db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
