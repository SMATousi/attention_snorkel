{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04752fd7-7493-4995-a2e7-65a52face286",
   "metadata": {},
   "source": [
    "# Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24248640-698e-42b0-a797-9bbb780674e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data with 3 features\n",
    "X, y = make_classification(n_samples=1000, n_features=3, n_informative=3, n_redundant=0,\n",
    "                           n_clusters_per_class=1, weights=[0.5, 0.5], flip_y=0.05, class_sep=1.5)\n",
    "\n",
    "# # Plotting the dataset\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Scatter plot for each class\n",
    "# ax.scatter(X[y == 0][:, 0], X[y == 0][:, 1], X[y == 0][:, 2], c='b', marker='o', label='Class 0')\n",
    "# ax.scatter(X[y == 1][:, 0], X[y == 1][:, 1], X[y == 1][:, 2], c='r', marker='^', label='Class 1')\n",
    "\n",
    "# ax.set_xlabel('Feature 1')\n",
    "# ax.set_ylabel('Feature 2')\n",
    "# ax.set_zlabel('Feature 3')\n",
    "# ax.set_title('3D Scatter Plot of Synthetic Data')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dceca30-496e-4019-8d1d-f989eadac7dd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0320cc-3b9f-43ee-a53d-5d5f1cbde817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Linear classifier model\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearClassifier(num_features=3)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Split data into training and testing\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for data, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(data).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be56b0c7-b96c-4e89-baba-f82d29fe5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the linear classifier on test data is: 95.50%\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in loader:\n",
    "            outputs = model(data).squeeze()\n",
    "            predicted = outputs.round()  # Threshold at 0.5\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Accuracy on the test set\n",
    "test_accuracy = calculate_accuracy(test_loader)\n",
    "print(f'Accuracy of the linear classifier on test data is: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725ef84-51d4-448c-856f-afebdecfe875",
   "metadata": {},
   "source": [
    "# Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b37e1b5-6185-4c81-be7c-9e8587d38fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def lf1(x):\n",
    "    # Label 1 if the first feature > 1, else 0\n",
    "    return (x[:, 0] > 1).float()\n",
    "\n",
    "def lf2(x):\n",
    "    # Label 1 if the second feature > 0, else 0\n",
    "    return (x[:, 1] > 2).float()\n",
    "\n",
    "def lf_classifier(x):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        # Ensure input is a PyTorch tensor and reshape it appropriately if it's just one sample\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        # Get the model's probability output\n",
    "        probabilities = model(x).squeeze()\n",
    "        \n",
    "        # Convert probabilities to binary labels based on a 0.5 threshold\n",
    "        labels = (probabilities >= 0.5).float()\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4ffb89d-28c6-4652-a1bb-477b1ad530e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd48ec7c-88c6-4165-ab77-1828fcba4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_lf1 = lf1(X_tensor)\n",
    "labels_lf2 = lf2(X_tensor)\n",
    "labels_lf3 = lf_classifier(X_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e0151-8178-4ab6-a9df-732e99404774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e3d36a-16ed-463f-9626-dac5b63a9088",
   "metadata": {},
   "source": [
    "# Generative Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57eafb0-f13f-41cf-98dc-970b18f65b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 100: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 200: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 300: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 400: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 500: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 600: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 700: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 800: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n",
      "Epoch 900: LF1 Acc = 0.5, LF2 Acc = 0.5, LF3 Acc = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize accuracy parameters for all three labeling functions\n",
    "acc_lf1 = torch.tensor(0.5, requires_grad=True)\n",
    "acc_lf2 = torch.tensor(0.5, requires_grad=True)\n",
    "acc_lf3 = torch.tensor(0.5, requires_grad=True)  # New parameter for the classifier LF\n",
    "\n",
    "# Optimizer includes the new accuracy parameter\n",
    "optimizer = torch.optim.Adam([acc_lf1, acc_lf2, acc_lf3], lr=0.01)\n",
    "\n",
    "# Define the training loop with marginal probability calculation including all three LFs\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Assuming binary class, calculate for both Y = 0 and Y = 1\n",
    "    # Marginal probabilities given Y=1\n",
    "    # acc_lf1 = torch.sigmoid(acc_lf1)\n",
    "    # acc_lf2 = torch.sigmoid(acc_lf2)\n",
    "    # acc_lf3 = torch.sigmoid(acc_lf3)\n",
    "    \n",
    "    p_lf1_given_y1 = acc_lf1 * labels_lf1 + (1 - acc_lf1) * (1 - labels_lf1)\n",
    "    p_lf2_given_y1 = acc_lf2 * labels_lf2 + (1 - acc_lf2) * (1 - labels_lf2)\n",
    "    p_lf3_given_y1 = acc_lf3 * labels_lf3 + (1 - acc_lf3) * (1 - labels_lf3)\n",
    "    \n",
    "    # Marginal probabilities given Y=0\n",
    "    p_lf1_given_y0 = (1 - acc_lf1) * labels_lf1 + acc_lf1 * (1 - labels_lf1)\n",
    "    p_lf2_given_y0 = (1 - acc_lf2) * labels_lf2 + acc_lf2 * (1 - labels_lf2)\n",
    "    p_lf3_given_y0 = (1 - acc_lf3) * labels_lf3 + acc_lf3 * (1 - labels_lf3)\n",
    "    \n",
    "    # Combine probabilities\n",
    "    joint_prob_y1 = p_lf1_given_y1 * p_lf2_given_y1 * p_lf3_given_y1\n",
    "    joint_prob_y0 = p_lf1_given_y0 * p_lf2_given_y0 * p_lf3_given_y0\n",
    "    \n",
    "    # Marginal probability over Y\n",
    "    total_prob = 0.5 * (joint_prob_y1 + joint_prob_y0)  # Assuming P(Y=1) = P(Y=0) = 0.5\n",
    "    \n",
    "    # Negative log likelihood\n",
    "    loss = -torch.log(total_prob + 1e-9).mean()  # small epsilon for numerical stability\n",
    "    \n",
    "    # Perform backpropagation\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: LF1 Acc = {acc_lf1.item()}, LF2 Acc = {acc_lf2.item()}, LF3 Acc = {acc_lf3.item()}\")\n",
    "\n",
    "# Optionally convert accuracy parameters to probabilities\n",
    "# acc_lf1_prob = torch.sigmoid(acc_lf1)\n",
    "# acc_lf2_prob = torch.sigmoid(acc_lf2)\n",
    "# acc_lf3_prob = torch.sigmoid(acc_lf3)\n",
    "# print(f\"Final Estimated Accuracies: LF1 = {acc_lf1_prob.item():.4f}, LF2 = {acc_lf2_prob.item():.4f}, LF3 = {acc_lf3_prob.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f607d403-747c-45ef-9af6-35c7928c5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 2075.951904296875\n",
      "Epoch 0: LF1 Acc = 0.5275577902793884, LF2 Acc = 0.5323365926742554, LF3 Acc = 0.5323490500450134\n",
      "Epoch 1: Loss = 2073.865234375\n",
      "Epoch 1: LF1 Acc = 0.5308534502983093, LF2 Acc = 0.5415493249893188, LF3 Acc = 0.5415723323822021\n",
      "Epoch 2: Loss = 2070.54833984375\n",
      "Epoch 2: LF1 Acc = 0.5350073575973511, LF2 Acc = 0.5530248284339905, LF3 Acc = 0.5530573725700378\n",
      "Epoch 3: Loss = 2065.435302734375\n",
      "Epoch 3: LF1 Acc = 0.5401578545570374, LF2 Acc = 0.5672008395195007, LF3 Acc = 0.5672426819801331\n",
      "Epoch 4: Loss = 2057.55810546875\n",
      "Epoch 4: LF1 Acc = 0.5464106202125549, LF2 Acc = 0.5844919085502625, LF3 Acc = 0.584542989730835\n",
      "Epoch 5: Loss = 2045.7607421875\n",
      "Epoch 5: LF1 Acc = 0.5537868142127991, LF2 Acc = 0.605189323425293, LF3 Acc = 0.6052497029304504\n",
      "Epoch 6: Loss = 2028.59716796875\n",
      "Epoch 6: LF1 Acc = 0.562155544757843, LF2 Acc = 0.6293123960494995, LF3 Acc = 0.629382312297821\n",
      "Epoch 7: Loss = 2004.819091796875\n",
      "Epoch 7: LF1 Acc = 0.5711721181869507, LF2 Acc = 0.6564450860023499, LF3 Acc = 0.6565252542495728\n",
      "Epoch 8: Loss = 1973.717529296875\n",
      "Epoch 8: LF1 Acc = 0.5802760124206543, LF2 Acc = 0.685652494430542, LF3 Acc = 0.6857424378395081\n",
      "Epoch 9: Loss = 1935.796875\n",
      "Epoch 9: LF1 Acc = 0.5887972116470337, LF2 Acc = 0.7155839800834656, LF3 Acc = 0.71568363904953\n",
      "Epoch 10: Loss = 1892.908447265625\n",
      "Epoch 10: LF1 Acc = 0.5961475372314453, LF2 Acc = 0.7447803616523743, LF3 Acc = 0.7448886036872864\n",
      "Epoch 11: Loss = 1847.8892822265625\n",
      "Epoch 11: LF1 Acc = 0.6019890904426575, LF2 Acc = 0.7720298171043396, LF3 Acc = 0.7721454501152039\n",
      "Epoch 12: Loss = 1803.4739990234375\n",
      "Epoch 12: LF1 Acc = 0.606278121471405, LF2 Acc = 0.7965850830078125, LF3 Acc = 0.7967058420181274\n",
      "Epoch 13: Loss = 1761.830810546875\n",
      "Epoch 13: LF1 Acc = 0.6091890931129456, LF2 Acc = 0.8181676268577576, LF3 Acc = 0.818292498588562\n",
      "Epoch 14: Loss = 1724.1719970703125\n",
      "Epoch 14: LF1 Acc = 0.6109985709190369, LF2 Acc = 0.8368456959724426, LF3 Acc = 0.8369736075401306\n",
      "Epoch 15: Loss = 1690.8763427734375\n",
      "Epoch 15: LF1 Acc = 0.6119930148124695, LF2 Acc = 0.8528807759284973, LF3 Acc = 0.8530107140541077\n",
      "Epoch 16: Loss = 1661.917724609375\n",
      "Epoch 16: LF1 Acc = 0.6124206185340881, LF2 Acc = 0.8666117787361145, LF3 Acc = 0.8667426705360413\n",
      "Epoch 17: Loss = 1636.8433837890625\n",
      "Epoch 17: LF1 Acc = 0.6124751567840576, LF2 Acc = 0.8783819079399109, LF3 Acc = 0.8785135746002197\n",
      "Epoch 18: Loss = 1615.1805419921875\n",
      "Epoch 18: LF1 Acc = 0.6122989058494568, LF2 Acc = 0.8885058164596558, LF3 Acc = 0.8886376619338989\n",
      "Epoch 19: Loss = 1596.4859619140625\n",
      "Epoch 19: LF1 Acc = 0.6119911670684814, LF2 Acc = 0.8972546458244324, LF3 Acc = 0.8973864316940308\n",
      "Epoch 20: Loss = 1580.278564453125\n",
      "Epoch 20: LF1 Acc = 0.6116187572479248, LF2 Acc = 0.9048563838005066, LF3 Acc = 0.9049879908561707\n",
      "Epoch 21: Loss = 1566.1951904296875\n",
      "Epoch 21: LF1 Acc = 0.6112249493598938, LF2 Acc = 0.9114992618560791, LF3 Acc = 0.9116304516792297\n",
      "Epoch 22: Loss = 1553.87353515625\n",
      "Epoch 22: LF1 Acc = 0.6108366847038269, LF2 Acc = 0.9173376560211182, LF3 Acc = 0.9174684882164001\n",
      "Epoch 23: Loss = 1543.0816650390625\n",
      "Epoch 23: LF1 Acc = 0.6104694604873657, LF2 Acc = 0.9224977493286133, LF3 Acc = 0.9226281642913818\n",
      "Epoch 24: Loss = 1533.5262451171875\n",
      "Epoch 24: LF1 Acc = 0.610131561756134, LF2 Acc = 0.9270832538604736, LF3 Acc = 0.9272130727767944\n",
      "Epoch 25: Loss = 1525.0675048828125\n",
      "Epoch 25: LF1 Acc = 0.609826385974884, LF2 Acc = 0.9311788082122803, LF3 Acc = 0.9313082098960876\n",
      "Epoch 26: Loss = 1517.519287109375\n",
      "Epoch 26: LF1 Acc = 0.6095542311668396, LF2 Acc = 0.9348545670509338, LF3 Acc = 0.9349834322929382\n",
      "Epoch 27: Loss = 1510.7706298828125\n",
      "Epoch 27: LF1 Acc = 0.6093138456344604, LF2 Acc = 0.938168466091156, LF3 Acc = 0.9382970929145813\n",
      "Epoch 28: Loss = 1504.7086181640625\n",
      "Epoch 28: LF1 Acc = 0.6091029047966003, LF2 Acc = 0.9411690831184387, LF3 Acc = 0.941297173500061\n",
      "Epoch 29: Loss = 1499.2225341796875\n",
      "Epoch 29: LF1 Acc = 0.6089186072349548, LF2 Acc = 0.9438965916633606, LF3 Acc = 0.9440244436264038\n",
      "Epoch 30: Loss = 1494.2490234375\n",
      "Epoch 30: LF1 Acc = 0.6087580323219299, LF2 Acc = 0.9463853240013123, LF3 Acc = 0.9465129375457764\n",
      "Epoch 31: Loss = 1489.7415771484375\n",
      "Epoch 31: LF1 Acc = 0.6086183190345764, LF2 Acc = 0.9486640095710754, LF3 Acc = 0.9487913846969604\n",
      "Epoch 32: Loss = 1485.6148681640625\n",
      "Epoch 32: LF1 Acc = 0.6084967851638794, LF2 Acc = 0.9507573246955872, LF3 Acc = 0.9508845210075378\n",
      "Epoch 33: Loss = 1481.8636474609375\n",
      "Epoch 33: LF1 Acc = 0.6083912253379822, LF2 Acc = 0.9526860117912292, LF3 Acc = 0.9528130292892456\n",
      "Epoch 34: Loss = 1478.394287109375\n",
      "Epoch 34: LF1 Acc = 0.6082993149757385, LF2 Acc = 0.9544683694839478, LF3 Acc = 0.9545952677726746\n",
      "Epoch 35: Loss = 1475.2164306640625\n",
      "Epoch 35: LF1 Acc = 0.6082191467285156, LF2 Acc = 0.9561198353767395, LF3 Acc = 0.956246554851532\n",
      "Epoch 36: Loss = 1472.27392578125\n",
      "Epoch 36: LF1 Acc = 0.6081491708755493, LF2 Acc = 0.957653820514679, LF3 Acc = 0.9577804207801819\n",
      "Epoch 37: Loss = 1469.537841796875\n",
      "Epoch 37: LF1 Acc = 0.6080878973007202, LF2 Acc = 0.9590822458267212, LF3 Acc = 0.9592087864875793\n",
      "Epoch 38: Loss = 1467.005615234375\n",
      "Epoch 38: LF1 Acc = 0.6080342531204224, LF2 Acc = 0.9604151844978333, LF3 Acc = 0.9605417251586914\n",
      "Epoch 39: Loss = 1464.6773681640625\n",
      "Epoch 39: LF1 Acc = 0.6079868674278259, LF2 Acc = 0.9616617560386658, LF3 Acc = 0.9617881774902344\n",
      "Epoch 40: Loss = 1462.487060546875\n",
      "Epoch 40: LF1 Acc = 0.6079451441764832, LF2 Acc = 0.9628297686576843, LF3 Acc = 0.9629563093185425\n",
      "Epoch 41: Loss = 1460.4561767578125\n",
      "Epoch 41: LF1 Acc = 0.6079081892967224, LF2 Acc = 0.963926374912262, LF3 Acc = 0.9640530347824097\n",
      "Epoch 42: Loss = 1458.5294189453125\n",
      "Epoch 42: LF1 Acc = 0.6078753471374512, LF2 Acc = 0.9649578332901001, LF3 Acc = 0.9650843739509583\n",
      "Epoch 43: Loss = 1456.7564697265625\n",
      "Epoch 43: LF1 Acc = 0.6078460812568665, LF2 Acc = 0.965929388999939, LF3 Acc = 0.9660561084747314\n",
      "Epoch 44: Loss = 1455.084716796875\n",
      "Epoch 44: LF1 Acc = 0.6078199744224548, LF2 Acc = 0.9668462872505188, LF3 Acc = 0.9669730067253113\n",
      "Epoch 45: Loss = 1453.5001220703125\n",
      "Epoch 45: LF1 Acc = 0.6077964901924133, LF2 Acc = 0.9677127003669739, LF3 Acc = 0.9678395390510559\n",
      "Epoch 46: Loss = 1452.015625\n",
      "Epoch 46: LF1 Acc = 0.6077753901481628, LF2 Acc = 0.9685328006744385, LF3 Acc = 0.9686597585678101\n",
      "Epoch 47: Loss = 1450.62890625\n",
      "Epoch 47: LF1 Acc = 0.6077563166618347, LF2 Acc = 0.96930992603302, LF3 Acc = 0.9694370031356812\n",
      "Epoch 48: Loss = 1449.3001708984375\n",
      "Epoch 48: LF1 Acc = 0.6077390909194946, LF2 Acc = 0.9700474739074707, LF3 Acc = 0.9701746106147766\n",
      "Epoch 49: Loss = 1448.0494384765625\n",
      "Epoch 49: LF1 Acc = 0.6077234148979187, LF2 Acc = 0.9707481861114502, LF3 Acc = 0.9708755016326904\n",
      "Epoch 50: Loss = 1446.8707275390625\n",
      "Epoch 50: LF1 Acc = 0.6077091693878174, LF2 Acc = 0.9714148044586182, LF3 Acc = 0.9715422987937927\n",
      "Epoch 51: Loss = 1445.7598876953125\n",
      "Epoch 51: LF1 Acc = 0.6076961159706116, LF2 Acc = 0.9720497131347656, LF3 Acc = 0.9721774458885193\n",
      "Epoch 52: Loss = 1444.70703125\n",
      "Epoch 52: LF1 Acc = 0.6076841354370117, LF2 Acc = 0.9726550579071045, LF3 Acc = 0.9727828502655029\n",
      "Epoch 53: Loss = 1443.6951904296875\n",
      "Epoch 53: LF1 Acc = 0.6076731085777283, LF2 Acc = 0.9732328057289124, LF3 Acc = 0.9733607769012451\n",
      "Epoch 54: Loss = 1442.729248046875\n",
      "Epoch 54: LF1 Acc = 0.6076630353927612, LF2 Acc = 0.9737846851348877, LF3 Acc = 0.9739128947257996\n",
      "Epoch 55: Loss = 1441.822509765625\n",
      "Epoch 55: LF1 Acc = 0.607653796672821, LF2 Acc = 0.9743125438690186, LF3 Acc = 0.9744409918785095\n",
      "Epoch 56: Loss = 1440.9580078125\n",
      "Epoch 56: LF1 Acc = 0.6076451539993286, LF2 Acc = 0.9748178720474243, LF3 Acc = 0.9749464392662048\n",
      "Epoch 57: Loss = 1440.130859375\n",
      "Epoch 57: LF1 Acc = 0.6076371073722839, LF2 Acc = 0.9753019213676453, LF3 Acc = 0.9754307866096497\n",
      "Epoch 58: Loss = 1439.350341796875\n",
      "Epoch 58: LF1 Acc = 0.6076297163963318, LF2 Acc = 0.9757660627365112, LF3 Acc = 0.97589510679245\n",
      "Epoch 59: Loss = 1438.5877685546875\n",
      "Epoch 59: LF1 Acc = 0.6076228022575378, LF2 Acc = 0.976211428642273, LF3 Acc = 0.9763407111167908\n",
      "Epoch 60: Loss = 1437.8843994140625\n",
      "Epoch 60: LF1 Acc = 0.6076164245605469, LF2 Acc = 0.9766392111778259, LF3 Acc = 0.9767687320709229\n",
      "Epoch 61: Loss = 1437.197509765625\n",
      "Epoch 61: LF1 Acc = 0.6076103448867798, LF2 Acc = 0.9770504236221313, LF3 Acc = 0.9771800637245178\n",
      "Epoch 62: Loss = 1436.518798828125\n",
      "Epoch 62: LF1 Acc = 0.6076048016548157, LF2 Acc = 0.9774457812309265, LF3 Acc = 0.9775757789611816\n",
      "Epoch 63: Loss = 1435.906494140625\n",
      "Epoch 63: LF1 Acc = 0.6075995564460754, LF2 Acc = 0.9778264760971069, LF3 Acc = 0.9779566526412964\n",
      "Epoch 64: Loss = 1435.285400390625\n",
      "Epoch 64: LF1 Acc = 0.6075945496559143, LF2 Acc = 0.9781930446624756, LF3 Acc = 0.9783234596252441\n",
      "Epoch 65: Loss = 1434.70703125\n",
      "Epoch 65: LF1 Acc = 0.6075899600982666, LF2 Acc = 0.9785464406013489, LF3 Acc = 0.9786770343780518\n",
      "Epoch 66: Loss = 1434.1676025390625\n",
      "Epoch 66: LF1 Acc = 0.6075855493545532, LF2 Acc = 0.9788872003555298, LF3 Acc = 0.9790180921554565\n",
      "Epoch 67: Loss = 1433.6219482421875\n",
      "Epoch 67: LF1 Acc = 0.6075814366340637, LF2 Acc = 0.9792160391807556, LF3 Acc = 0.9793471693992615\n",
      "Epoch 68: Loss = 1433.118408203125\n",
      "Epoch 68: LF1 Acc = 0.6075775623321533, LF2 Acc = 0.9795335531234741, LF3 Acc = 0.9796650409698486\n",
      "Epoch 69: Loss = 1432.62841796875\n",
      "Epoch 69: LF1 Acc = 0.607573926448822, LF2 Acc = 0.9798403382301331, LF3 Acc = 0.9799720644950867\n",
      "Epoch 70: Loss = 1432.154541015625\n",
      "Epoch 70: LF1 Acc = 0.6075704097747803, LF2 Acc = 0.9801368713378906, LF3 Acc = 0.9802687764167786\n",
      "Epoch 71: Loss = 1431.6890869140625\n",
      "Epoch 71: LF1 Acc = 0.6075671315193176, LF2 Acc = 0.9804236888885498, LF3 Acc = 0.9805559515953064\n",
      "Epoch 72: Loss = 1431.260009765625\n",
      "Epoch 72: LF1 Acc = 0.6075640916824341, LF2 Acc = 0.980701208114624, LF3 Acc = 0.9808337092399597\n",
      "Epoch 73: Loss = 1430.8157958984375\n",
      "Epoch 73: LF1 Acc = 0.6075610518455505, LF2 Acc = 0.9809699058532715, LF3 Acc = 0.9811027646064758\n",
      "Epoch 74: Loss = 1430.4234619140625\n",
      "Epoch 74: LF1 Acc = 0.6075583696365356, LF2 Acc = 0.9812301397323608, LF3 Acc = 0.9813632965087891\n",
      "Epoch 75: Loss = 1430.0413818359375\n",
      "Epoch 75: LF1 Acc = 0.6075556874275208, LF2 Acc = 0.9814823865890503, LF3 Acc = 0.9816158413887024\n",
      "Epoch 76: Loss = 1429.6480712890625\n",
      "Epoch 76: LF1 Acc = 0.6075531840324402, LF2 Acc = 0.9817270040512085, LF3 Acc = 0.9818606376647949\n",
      "Epoch 77: Loss = 1429.2796630859375\n",
      "Epoch 77: LF1 Acc = 0.6075506806373596, LF2 Acc = 0.9819642305374146, LF3 Acc = 0.9820981621742249\n",
      "Epoch 78: Loss = 1428.929931640625\n",
      "Epoch 78: LF1 Acc = 0.6075484752655029, LF2 Acc = 0.9821943640708923, LF3 Acc = 0.9823285937309265\n",
      "Epoch 79: Loss = 1428.583984375\n",
      "Epoch 79: LF1 Acc = 0.6075462698936462, LF2 Acc = 0.9824178814888, LF3 Acc = 0.9825524091720581\n",
      "Epoch 80: Loss = 1428.249267578125\n",
      "Epoch 80: LF1 Acc = 0.6075441837310791, LF2 Acc = 0.9826349020004272, LF3 Acc = 0.9827698469161987\n",
      "Epoch 81: Loss = 1427.9366455078125\n",
      "Epoch 81: LF1 Acc = 0.6075421571731567, LF2 Acc = 0.9828458428382874, LF3 Acc = 0.9829809665679932\n",
      "Epoch 82: Loss = 1427.6214599609375\n",
      "Epoch 82: LF1 Acc = 0.6075402498245239, LF2 Acc = 0.9830507636070251, LF3 Acc = 0.9831862449645996\n",
      "Epoch 83: Loss = 1427.3248291015625\n",
      "Epoch 83: LF1 Acc = 0.6075384616851807, LF2 Acc = 0.983250081539154, LF3 Acc = 0.9833858609199524\n",
      "Epoch 84: Loss = 1427.0428466796875\n",
      "Epoch 84: LF1 Acc = 0.6075367331504822, LF2 Acc = 0.9834439754486084, LF3 Acc = 0.9835800528526306\n",
      "Epoch 85: Loss = 1426.7548828125\n",
      "Epoch 85: LF1 Acc = 0.6075350046157837, LF2 Acc = 0.9836326241493225, LF3 Acc = 0.9837691187858582\n",
      "Epoch 86: Loss = 1426.4898681640625\n",
      "Epoch 86: LF1 Acc = 0.6075334548950195, LF2 Acc = 0.9838162660598755, LF3 Acc = 0.983953058719635\n",
      "Epoch 87: Loss = 1426.20556640625\n",
      "Epoch 87: LF1 Acc = 0.6075319051742554, LF2 Acc = 0.9839950799942017, LF3 Acc = 0.9841320514678955\n",
      "Epoch 88: Loss = 1425.9644775390625\n",
      "Epoch 88: LF1 Acc = 0.6075304746627808, LF2 Acc = 0.9841692447662354, LF3 Acc = 0.9843065738677979\n",
      "Epoch 89: Loss = 1425.715576171875\n",
      "Epoch 89: LF1 Acc = 0.6075290441513062, LF2 Acc = 0.9843388795852661, LF3 Acc = 0.984476625919342\n",
      "Epoch 90: Loss = 1425.4718017578125\n",
      "Epoch 90: LF1 Acc = 0.6075276732444763, LF2 Acc = 0.9845043420791626, LF3 Acc = 0.9846423268318176\n",
      "Epoch 91: Loss = 1425.2371826171875\n",
      "Epoch 91: LF1 Acc = 0.6075263619422913, LF2 Acc = 0.9846656322479248, LF3 Acc = 0.9848039150238037\n",
      "Epoch 92: Loss = 1425.01513671875\n",
      "Epoch 92: LF1 Acc = 0.607525110244751, LF2 Acc = 0.9848228693008423, LF3 Acc = 0.9849615097045898\n",
      "Epoch 93: Loss = 1424.79833984375\n",
      "Epoch 93: LF1 Acc = 0.6075238585472107, LF2 Acc = 0.9849763512611389, LF3 Acc = 0.9851152300834656\n",
      "Epoch 94: Loss = 1424.5692138671875\n",
      "Epoch 94: LF1 Acc = 0.60752272605896, LF2 Acc = 0.9851260185241699, LF3 Acc = 0.98526531457901\n",
      "Epoch 95: Loss = 1424.3739013671875\n",
      "Epoch 95: LF1 Acc = 0.607521653175354, LF2 Acc = 0.9852721691131592, LF3 Acc = 0.9854118227958679\n",
      "Epoch 96: Loss = 1424.1708984375\n",
      "Epoch 96: LF1 Acc = 0.607520580291748, LF2 Acc = 0.9854148626327515, LF3 Acc = 0.9855548143386841\n",
      "Epoch 97: Loss = 1423.9776611328125\n",
      "Epoch 97: LF1 Acc = 0.6075195074081421, LF2 Acc = 0.9855542182922363, LF3 Acc = 0.9856944680213928\n",
      "Epoch 98: Loss = 1423.787109375\n",
      "Epoch 98: LF1 Acc = 0.6075184941291809, LF2 Acc = 0.9856902956962585, LF3 Acc = 0.9858309626579285\n",
      "Epoch 99: Loss = 1423.60595703125\n",
      "Epoch 99: LF1 Acc = 0.6075175404548645, LF2 Acc = 0.985823392868042, LF3 Acc = 0.985964298248291\n"
     ]
    }
   ],
   "source": [
    "# Initialize accuracy parameters for all three labeling functions\n",
    "acc_lf1 = torch.tensor(0.1, requires_grad=True)\n",
    "acc_lf2 = torch.tensor(0.1, requires_grad=True)\n",
    "acc_lf3 = torch.tensor(0.1, requires_grad=True)  # New parameter for the classifier LF\n",
    "\n",
    "# Optimizer includes the new accuracy parameter\n",
    "optimizer = torch.optim.SGD([acc_lf1, acc_lf2, acc_lf3], lr=0.001)\n",
    "\n",
    "# Batch size for mini-batch SGD (1 for true SGD, larger for mini-batch SGD)\n",
    "batch_size = 1  # Change this to larger sizes like 64, 128, etc., for mini-batch SGD\n",
    "\n",
    "# DataLoader for iterating through the data\n",
    "data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_tensor, y_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    initial_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for data in data_loader:\n",
    "        \n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        x_batch, _ = data  # We do not use y_tensor since we are estimating LF accuracies\n",
    "        \n",
    "\n",
    "        labels_lf1_batch = lf1(x_batch)\n",
    "        labels_lf2_batch = lf2(x_batch)\n",
    "        labels_lf3_batch = lf_classifier(x_batch)  # Assuming lf_classifier is prepared for batch processing\n",
    "\n",
    "        # Compute probabilities for each label function and each class\n",
    "        # Similar to previous code, but applied to the batch\n",
    "        # p_lf1_given_y1 = acc_lf1 * labels_lf1_batch + (1 - acc_lf1) * (1 - labels_lf1_batch)\n",
    "        # p_lf2_given_y1 = acc_lf2 * labels_lf2_batch + (1 - acc_lf2) * (1 - labels_lf2_batch)\n",
    "        # p_lf3_given_y1 = acc_lf3 * labels_lf3_batch + (1 - acc_lf3) * (1 - labels_lf3_batch)\n",
    "        \n",
    "        # p_lf1_given_y0 = (1 - acc_lf1) * labels_lf1_batch + acc_lf1 * (1 - labels_lf1_batch)\n",
    "        # p_lf2_given_y0 = (1 - acc_lf2) * labels_lf2_batch + acc_lf2 * (1 - labels_lf2_batch)\n",
    "        # p_lf3_given_y0 = (1 - acc_lf3) * labels_lf3_batch + acc_lf3 * (1 - labels_lf3_batch)\n",
    "\n",
    "        p_lf1_given_y1 = torch.sigmoid(acc_lf1) * labels_lf1_batch + (1 - torch.sigmoid(acc_lf1)) * (1 - labels_lf1_batch)\n",
    "        p_lf2_given_y1 = torch.sigmoid(acc_lf2) * labels_lf2_batch + (1 - torch.sigmoid(acc_lf2)) * (1 - labels_lf2_batch)\n",
    "        p_lf3_given_y1 = torch.sigmoid(acc_lf3) * labels_lf3_batch + (1 - torch.sigmoid(acc_lf3)) * (1 - labels_lf3_batch)\n",
    "        \n",
    "        p_lf1_given_y0 = (1 - torch.sigmoid(acc_lf1)) * labels_lf1_batch + torch.sigmoid(acc_lf1) * (1 - labels_lf1_batch)\n",
    "        p_lf2_given_y0 = (1 - torch.sigmoid(acc_lf2)) * labels_lf2_batch + torch.sigmoid(acc_lf2) * (1 - labels_lf2_batch)\n",
    "        p_lf3_given_y0 = (1 - torch.sigmoid(acc_lf3)) * labels_lf3_batch + torch.sigmoid(acc_lf3) * (1 - labels_lf3_batch)\n",
    "        \n",
    "        joint_prob_y1 = p_lf1_given_y1 * p_lf2_given_y1 * p_lf3_given_y1\n",
    "        joint_prob_y0 = p_lf1_given_y0 * p_lf2_given_y0 * p_lf3_given_y0\n",
    "        \n",
    "        total_prob = 0.5 * (joint_prob_y1 + joint_prob_y0)\n",
    "        \n",
    "        loss = -torch.log(total_prob + 1e-9).mean()\n",
    "\n",
    "        initial_loss = initial_loss + loss\n",
    "        \n",
    "    initial_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {initial_loss.item()}\")\n",
    "        print(f\"Epoch {epoch}: LF1 Acc = {torch.sigmoid(acc_lf1).item()}, LF2 Acc = {torch.sigmoid(acc_lf2).item()}, LF3 Acc = {torch.sigmoid(acc_lf3).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcc49b-8a48-4054-914f-a1df906ed06c",
   "metadata": {},
   "source": [
    "# Classifying Using Noise-Aware Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47940c44-a12b-4221-a439-9048f7823226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Create a dataset\n",
    "full_dataset = TensorDataset(X_tensor, y_tensor)  # Assuming y_tensor is the true labels\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Output is a single value (logit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # Returns logits\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation during inference\n",
    "        for data, labels in data_loader:\n",
    "            outputs = model(data)\n",
    "            predicted = torch.sigmoid(outputs).round()  # Convert logits to binary predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "101ce7ff-d865-42ca-bdab-f7e6e27ec89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4250\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb02ea7-21db-4f21-9b46-623160cf9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_aware_loss(logits, labels, acc_lfs):\n",
    "    \"\"\"\n",
    "    logits: output from the model\n",
    "    labels: labels from labeling functions\n",
    "    acc_lfs: accuracies of the labeling functions\n",
    "    \"\"\"\n",
    "    sigmoids = torch.sigmoid(logits)\n",
    "    loss = 0\n",
    "    for i, acc in enumerate(acc_lfs):\n",
    "        # Estimated probability of true label being 1 given the label from LF\n",
    "        p_y_given_lf1 = labels[:, i] * acc + (1 - labels[:, i]) * (1 - acc)\n",
    "        # Binary cross-entropy term for each LF\n",
    "        loss += -p_y_given_lf1 * torch.log(sigmoids) - (1 - p_y_given_lf1) * torch.log(1 - sigmoids)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3746d374-af4f-401f-a4fe-ebf37dfcfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_aware_loss(logits, labels, acc_lfs):\n",
    "    sigmoids = torch.sigmoid(logits)\n",
    "    loss = 0\n",
    "    for i, acc in enumerate(acc_lfs):\n",
    "        \n",
    "        p_y_given_lf = labels[:, i] * acc + (1 - labels[:, i]) * (1 - acc)\n",
    "        \n",
    "        loss += -p_y_given_lf * torch.log(sigmoids + 1e-9) - (1 - p_y_given_lf) * torch.log(1 - sigmoids + 1e-9)\n",
    "        \n",
    "    return loss.mean()\n",
    "\n",
    "# Accuracies estimated from previous steps, converted to a tensor\n",
    "acc_lfs = torch.tensor([acc_lf1.item(), acc_lf2.item(), acc_lf3.item()], requires_grad=False)\n",
    "\n",
    "# Labels matrix combining all labeling functions\n",
    "labels_matrix = torch.stack([labels_lf1, labels_lf2, labels_lf3], dim=1).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "699b868d-0280-4a36-997c-e48fd8ae5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Average Loss = -4.317668999616917\n",
      "Epoch 10: Average Loss = -28.560574311476486\n",
      "Epoch 20: Average Loss = -34.28257245283861\n",
      "Epoch 30: Average Loss = -62.868141174316406\n",
      "Epoch 40: Average Loss = -71.62599101433388\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(input_dim=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 50\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, targets in train_loader:\n",
    "        target_labels = torch.tensor(np.array([lf1(data),lf2(data),lf_classifier(data)]))\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)\n",
    "        \n",
    "        loss = noise_aware_loss(logits, target_labels, acc_lfs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}: Average Loss = {total_loss / len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ad337fd-29b6-4fc0-9892-60c5d8e21266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1154.9387950897217"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a228af-8dc4-48f3-9969-f77cd5394024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
